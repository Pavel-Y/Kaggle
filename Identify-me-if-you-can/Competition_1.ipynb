{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "PATH_TO_DATA = 'data/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cols = ['time%d' % i for i in range(1, 11)]\n",
    "site_cols = ['site%d' % i for i in range(1, 11)]\n",
    "\n",
    "train_df = pd.read_csv(PATH_TO_DATA +'train_sessions_400users.csv', index_col='session_id', parse_dates=time_cols)\n",
    "test_df = pd.read_csv(PATH_TO_DATA + 'test_sessions_400users.csv', index_col='session_id', parse_dates=time_cols)\n",
    "\n",
    "with open(PATH_TO_DATA + 'site_dic.pkl', 'rb') as site_file:\n",
    "     sites_dict = pickle.load(site_file)\n",
    "        \n",
    "id_sites_dict = {v: k for k, v in sites_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file, target='user_id', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels, index = np.arange(1, predicted_labels.shape[0] + 1), columns=[target])\n",
    "    predicted_df.to_csv(PATH_TO_DATA + out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X_data, y_data):\n",
    "    grouped = train_df[['user_id']].groupby(by='user_id')\n",
    "    \n",
    "    train_ids = []\n",
    "    valid_ids = []\n",
    "    \n",
    "    for g in tqdm(grouped.groups.keys()):\n",
    "        train_shape = int(grouped.get_group(g).shape[0] * 0.7)\n",
    "\n",
    "        ids_to_train = grouped.get_group(g).index[:train_shape]\n",
    "        ids_to_valid = grouped.get_group(g).index[train_shape:]\n",
    "\n",
    "        train_ids.extend(ids_to_train)\n",
    "        valid_ids.extend(ids_to_valid)\n",
    "        \n",
    "    train_ids = np.array(train_ids) - 1\n",
    "    valid_ids = np.array(valid_ids) - 1\n",
    "        \n",
    "    return X_data.tocsc()[train_ids], y_data[train_ids], X_data.tocsc()[valid_ids], y_data[valid_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_features(data):\n",
    "#     row_size = 26\n",
    "#     morning_offset = 24\n",
    "#     evening_offset = 25\n",
    "    values = []\n",
    "    \n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        \n",
    "        time = row[time_cols[0]]\n",
    "    \n",
    "        r = np.zeros(24)\n",
    "        r[time.hour - 1] += 1\n",
    "#         r[morning_offset] = time.hour < 11\n",
    "#         r[evening_offset] = time.hour > 19\n",
    "        values.append(r)\n",
    "        \n",
    "    return csr_matrix(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_matrix(matrix):\n",
    "    site_ids = list(id_sites_dict)\n",
    "    X = matrix.values\n",
    "    \n",
    "    i = 0\n",
    "    data = list()\n",
    "    col = list()\n",
    "    rows = list()\n",
    "    for row in tqdm(X):\n",
    "        unique, counts = np.unique(row, return_counts=True)\n",
    "        dic = dict(zip(unique, counts))\n",
    "        for k in dic:\n",
    "            if (k == 0):\n",
    "                continue\n",
    "            \n",
    "            data.append(dic[k])\n",
    "            rows.append(i)\n",
    "            col.append(k-1)\n",
    "            \n",
    "        i += 1\n",
    "    X_sparse = csr_matrix((data, (rows, col)), shape=(X.shape[0], len(site_ids)))\n",
    "    return X_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, X_train, y_train, X_valid, y_valid):\n",
    "    model.fit(X_train, y_train)\n",
    "    valid_score = model.predict(X_valid)\n",
    "    print(accuracy_score(y_valid, valid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_month(data):\n",
    "    time = time_cols[0]\n",
    "    values = [row[time].year * 100 + row[time].month for _, row in tqdm(data.iterrows())]\n",
    "    series = pd.Series(values)\n",
    "    return csr_matrix(pd.get_dummies(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_part_of_day(data):\n",
    "    time = time_cols[0]\n",
    "    values = [row[time].hour // 6 for _, row in tqdm(data.iterrows())]\n",
    "    series = pd.Series(values)\n",
    "    return csr_matrix(pd.get_dummies(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weekend(data):\n",
    "    time = time_cols[0]\n",
    "    values = [[row[time].dayofweek > 4] for _, row in tqdm(data.iterrows())]\n",
    "    return csr_matrix(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_duration(data):\n",
    "    values = []\n",
    "    time = time_cols[0]\n",
    "\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "\n",
    "        first = row[time]\n",
    "        last = first\n",
    "\n",
    "        for t, check in zip(time_cols, row.values == np.datetime64('NaT')):\n",
    "            if check:\n",
    "                break\n",
    "            else:\n",
    "                last = row[t]\n",
    "\n",
    "        values.append([np.log1p(last.minute - first.minute)])\n",
    "\n",
    "    return csr_matrix(np.nan_to_num(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_week(data):\n",
    "    time = time_cols[0]\n",
    "    values = []\n",
    "    \n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        \n",
    "        r = np.zeros(53)\n",
    "        r[row[time].week] = 1\n",
    "        values.append(r)\n",
    "        \n",
    "    return csr_matrix(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test(data, train_size):\n",
    "    return data.tocsc()[:train_size], data.tocsc()[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_sites_df = pd.concat([train_df[site_cols].fillna(0).astype('int'), test_df[site_cols].fillna(0).astype('int')])\n",
    "train_test_times_df = pd.concat([train_df[time_cols], test_df[time_cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 229266/229266 [00:07<00:00, 30830.70it/s]\n",
      "229266it [00:15, 15027.50it/s]\n",
      "229266it [00:18, 12133.23it/s]\n",
      "229266it [00:14, 16107.96it/s]\n",
      "229266it [00:15, 14983.87it/s]\n",
      "229266it [01:02, 3651.85it/s]\n",
      "229266it [00:23, 9725.33it/s] \n"
     ]
    }
   ],
   "source": [
    "X_tmp_sparse = get_dense_matrix(train_test_sites_df)\n",
    "X_tmp_time_features = extract_time_features(train_test_times_df)\n",
    "# X_tmp_unique = unique(train_test_sites_df)\n",
    "\n",
    "X_tmp_year_month = extract_year_month(train_test_times_df)\n",
    "X_tmp_part_of_day = extract_part_of_day(train_test_times_df)\n",
    "X_tmp_weekend = extract_weekend(train_test_times_df)\n",
    "X_tmp_duration = extract_duration(train_test_times_df)\n",
    "X_tmp_weeks = extract_week(train_test_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_sparse = hstack((X_tmp_sparse, \n",
    "                       X_tmp_time_features, \n",
    "#                      X_tmp_unique, \n",
    "                       X_tmp_year_month, \n",
    "                       X_tmp_part_of_day, \n",
    "                       X_tmp_weekend,\n",
    "                       X_tmp_duration,\n",
    "                       X_tmp_weeks\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['user_id'].values.astype('int64')\n",
    "X_train_sparse, X_test_sparse = split_train_and_test(X_tmp_sparse, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(C=2.11111111111, n_jobs=-1)\n",
    "logit.fit(X_train_sparse, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit.predict(X_test_sparse)\n",
    "write_to_submission_file(logit_test_pred.astype(int), 'results1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182793it [00:07, 25877.78it/s]\n",
      "46473it [00:02, 21470.21it/s]\n"
     ]
    }
   ],
   "source": [
    "str_train = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in tqdm(train_df[site_cols].iterrows())]\n",
    "str_test = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in tqdm(test_df[site_cols].iterrows())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 3)).fit(np.array(str_train))\n",
    "X_train_idf = tfidf.transform(np.array(str_train))\n",
    "X_test_idf = tfidf.transform(np.array(str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_idf = hstack((vstack((X_train_idf, X_test_idf)), \n",
    "                            X_tmp_time_features, \n",
    "#                             X_tmp_unique, \n",
    "                            X_tmp_year_month, \n",
    "                            X_tmp_part_of_day, \n",
    "                            X_tmp_weekend,\n",
    "                            X_tmp_duration,\n",
    "                            X_tmp_weeks\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['user_id'].values.astype('int64')\n",
    "X_train_idf, X_test_idf = split_train_and_test(X_tmp_idf, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit_idf = LogisticRegression(C=2.11111111111, n_jobs=-1)\n",
    "logit_idf.fit(X_train_idf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit_idf.predict(X_test_idf)\n",
    "write_to_submission_file(logit_test_pred.astype(int), 'results2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182793, 36762), (182793, 308860), (182793,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape, X_train_idf.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = get_dense_matrix(train_df[site_cols].fillna(0).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 400/400 [00:00<00:00, 553.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((378287, 36682), (378287,), (162387, 36682), (162387,))"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp = hstack((X_train_sparse, extract_time_features(train_df[time_cols])))\n",
    "X_train, y_train, X_valid, y_valid = split_data(X_tmp, train_df['user_id'].values.astype('int64'))\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.256110402926\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score(SGDClassifier(random_state=17, n_jobs=-1, loss='log'), X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_tmp\n",
    "y = new_data['user_id'].values.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7h 15min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(C=2.11111111111, n_jobs=-1)\n",
    "logit.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = hstack((X_test_idf, extract_time_features(test_df[time_cols])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit.predict(X_test)\n",
    "write_to_submission_file(logit_test_pred.astype(int), 'results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(logit_test_pred.astype(int), 'results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result which I can get is 0.20218 that is the 9 place out of 119. Not bad, but will see how it will go on private leaderboard. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
