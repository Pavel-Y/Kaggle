{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from __future__ import division, print_function\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import clone\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "PATH_TO_DATA = 'data/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cols = ['time%d' % i for i in range(1, 11)]\n",
    "site_cols = ['site%d' % i for i in range(1, 11)]\n",
    "\n",
    "train_df = pd.read_csv(PATH_TO_DATA + 'train_sessions.csv', index_col='session_id', parse_dates=time_cols)\n",
    "test_df = pd.read_csv(PATH_TO_DATA + 'test_sessions.csv', index_col='session_id', parse_dates=time_cols)\n",
    "\n",
    "with open(PATH_TO_DATA + 'site_dic.pkl', 'rb') as site_file:\n",
    "     sites_dict = pickle.load(site_file)\n",
    "        \n",
    "id_sites_dict = {v: k for k, v in sites_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X_data, y_data):\n",
    "    grouped = train_df[['target']].groupby(by='target')\n",
    "    \n",
    "    train_ids = []\n",
    "    valid_ids = []\n",
    "    \n",
    "    for g in tqdm(grouped.groups.keys()):\n",
    "        train_shape = int(grouped.get_group(g).shape[0] * 0.7)\n",
    "\n",
    "        ids_to_train = grouped.get_group(g).index[:train_shape]\n",
    "        ids_to_valid = grouped.get_group(g).index[train_shape:]\n",
    "\n",
    "        train_ids.extend(ids_to_train)\n",
    "        valid_ids.extend(ids_to_valid)\n",
    "        \n",
    "    train_ids = np.array(train_ids) - 1\n",
    "    valid_ids = np.array(valid_ids) - 1\n",
    "        \n",
    "    return X_data.tocsc()[train_ids], y_data[train_ids], X_data.tocsc()[valid_ids], y_data[valid_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_matrix(matrix):\n",
    "    site_ids = list(id_sites_dict)\n",
    "    X = matrix.values\n",
    "    \n",
    "    i = 0\n",
    "    data = list()\n",
    "    col = list()\n",
    "    rows = list()\n",
    "    for row in tqdm(X):\n",
    "        unique, counts = np.unique(row, return_counts=True)\n",
    "        dic = dict(zip(unique, counts))\n",
    "        for k in dic:\n",
    "            if k != 0:\n",
    "                data.append(dic[k])\n",
    "                rows.append(i)\n",
    "                col.append(k-1)\n",
    "            \n",
    "        i += 1\n",
    "    X_sparse = csr_matrix((data, (rows, col)), shape=(X.shape[0], len(site_ids)))\n",
    "    return X_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, X_train, y_train, X_valid, y_valid):\n",
    "    model.fit(X_train, y_train)\n",
    "    valid_score = model.predict_proba(X_valid)\n",
    "    print(roc_auc_score(y_valid, valid_score[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file, target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels, index = np.arange(1, predicted_labels.shape[0] + 1), columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(model, X_train, y_train, X_test):\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred_proba = model.predict_proba(X_test)\n",
    "    write_to_submission_file(test_pred_proba[:, 1:], 'result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exptact_time_features(data):\n",
    "\n",
    "    day_offset = 24\n",
    "    month_offset = day_offset + 7\n",
    "    morning_offset = month_offset + 12\n",
    "    evening_offset = morning_offset + 1\n",
    "    row_size = evening_offset + 2\n",
    "    values = []\n",
    "\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        \n",
    "        time = row[time_cols[0]]\n",
    "\n",
    "        r = np.zeros(row_size)\n",
    "        r[time.hour] += 1\n",
    "        r[day_offset + time.dayofweek] += 1\n",
    "        r[month_offset + time.month] += 1\n",
    "        r[morning_offset] = time.hour < 11\n",
    "        r[evening_offset] = time.hour > 19\n",
    "        values.append(r[1:])\n",
    "        \n",
    "    return csr_matrix(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(data):\n",
    "    return csr_matrix([[sum(1 for s in np.unique(row.values) if s != 0)] for _, row in tqdm(data.iterrows())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_train = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in train_df[site_cols].iterrows()]\n",
    "str_test = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in test_df[site_cols].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 2)).fit(np.array(str_train))\n",
    "X_train_idf = tfidf.transform(np.array(str_train))\n",
    "X_test_idf = tfidf.transform(np.array(str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:19, 13046.28it/s]\n",
      "253561it [00:19, 13014.67it/s]\n",
      "82797it [00:06, 12494.42it/s]\n",
      "82797it [00:07, 11125.20it/s]\n"
     ]
    }
   ],
   "source": [
    "X_tmp_train = hstack((X_train_idf, \n",
    "                      exptact_time_features(train_df[time_cols]),\n",
    "                      unique(train_df[site_cols].fillna(0).astype('int'))))\n",
    "\n",
    "X_tmp_test = hstack((X_test_idf, \n",
    "                     exptact_time_features(test_df[time_cols]),\n",
    "                     unique(test_df[site_cols].fillna(0).astype('int'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 39.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((177491, 129384), (177491,), (76070, 129384), (76070,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid = split_data(X_tmp_train, train_df['target'].values.astype('int64'))\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit_c_values = np.logspace(-4, 2, 10)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=17)\n",
    "\n",
    "logit_grid_searcher = LogisticRegressionCV(Cs=logit_c_values, cv=skf, n_jobs=-1)\n",
    "logit_grid_searcher.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.544347     0.995014\n",
       "100.000000    0.994929\n",
       "4.641589      0.994867\n",
       "1.000000      0.994011\n",
       "0.215443      0.993081\n",
       "0.046416      0.991966\n",
       "0.010000      0.990946\n",
       "0.002154      0.990946\n",
       "0.000464      0.990946\n",
       "0.000100      0.990946\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mean_cv_scores = next (iter (logit_grid_searcher.scores_.values())).mean(axis=0)\n",
    "pd.Series(logit_mean_cv_scores, index=logit_grid_searcher.Cs_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990094285571\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 129384)\n",
      "(82797, 129384)\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = train_df['target'].values.astype('int64')\n",
    "make_submission(LogisticRegression(C=21.544347, n_jobs=-1), X_tmp_train, y, X_tmp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 253561/253561 [00:08<00:00, 28589.36it/s]\n",
      "253561it [00:19, 13235.60it/s]\n",
      "253561it [00:23, 10843.80it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_sparse = get_dense_matrix(train_df[site_cols].fillna(0).astype('int'))\n",
    "X_train_time_features = exptact_time_features(train_df[time_cols])\n",
    "X_Train_unique = unique(train_df[site_cols].fillna(0).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_train = hstack((X_train_sparse, X_train_time_features, X_Train_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 38.07it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid = split_data(X_tmp_train, train_df['target'].values.astype('int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    175884\n",
       "1      1607\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75380\n",
       "1      690\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_valid).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tmp_train, y, train_size =0.7, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    175884\n",
       "1      1608\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75380\n",
       "1      689\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_valid).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, X, y, train_size=0.7, random_states=[1, 13, 42]):\n",
    "    result = []\n",
    "    \n",
    "    for rs in random_states:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=train_size, stratify=y, random_state=rs)\n",
    "        m = clone(model, safe=True)\n",
    "        m.fit(X_train, y_train)\n",
    "        valid_score = m.predict_proba(X_valid)\n",
    "        result.append(roc_auc_score(y_valid, valid_score[:, 1:]))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988449523864\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.98693736928830067, 0.98689524117957172, 0.98942301434704705]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_tmp_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_df[time_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>time5</th>\n",
       "      <th>time6</th>\n",
       "      <th>time7</th>\n",
       "      <th>time8</th>\n",
       "      <th>time9</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-20 10:02:45</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>2014-02-22 11:20:15</td>\n",
       "      <td>2014-02-22 11:20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-16 16:40:17</td>\n",
       "      <td>2013-12-16 16:40:18</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:20</td>\n",
       "      <td>2013-12-16 16:40:21</td>\n",
       "      <td>2013-12-16 16:40:22</td>\n",
       "      <td>2013-12-16 16:40:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time1               time2               time3  \\\n",
       "session_id                                                               \n",
       "1          2014-02-20 10:02:45                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:50 2014-02-22 11:19:50 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:17 2013-12-16 16:40:18 2013-12-16 16:40:19   \n",
       "\n",
       "                         time4               time5               time6  \\\n",
       "session_id                                                               \n",
       "1                          NaT                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:51 2014-02-22 11:19:51 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:19 2013-12-16 16:40:19 2013-12-16 16:40:19   \n",
       "\n",
       "                         time7               time8               time9  \\\n",
       "session_id                                                               \n",
       "1                          NaT                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:52 2014-02-22 11:19:52 2014-02-22 11:20:15   \n",
       "3          2013-12-16 16:40:20 2013-12-16 16:40:21 2013-12-16 16:40:22   \n",
       "\n",
       "                        time10  \n",
       "session_id                      \n",
       "1                          NaT  \n",
       "2          2014-02-22 11:20:16  \n",
       "3          2013-12-16 16:40:24  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_month(data):\n",
    "    time = time_cols[0]\n",
    "    values = [row[time].year * 100 + row[time].month for _, row in tqdm(data.iterrows())]\n",
    "    series = pd.Series(values)\n",
    "    return csr_matrix(pd.get_dummies(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:21, 11855.27it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_year_month = extract_year_month(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_year_month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.98709390563380672, 0.98705002539624109, 0.98953470774683538]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_part_of_day(data):\n",
    "    time = time_cols[0]\n",
    "    values = [row[time].hour // 6 for _, row in tqdm(data.iterrows())]\n",
    "    series = pd.Series(values)\n",
    "    return csr_matrix(pd.get_dummies(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:17, 14888.16it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_part_of_day = extract_part_of_day(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_part_of_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.98697543476862848, 0.98692448825322765, 0.98928734951427533]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weekend(data):\n",
    "    time = time_cols[0]\n",
    "    values = [[row[time].dayofweek > 4] for _, row in tqdm(data.iterrows())]\n",
    "    return csr_matrix(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:17, 14645.33it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_weekend = extract_weekend(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_weekend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.98692604784043392, 0.98690698621902528, 0.98941088422433254]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_df[time_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>time5</th>\n",
       "      <th>time6</th>\n",
       "      <th>time7</th>\n",
       "      <th>time8</th>\n",
       "      <th>time9</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-20 10:02:45</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>2014-02-22 11:20:15</td>\n",
       "      <td>2014-02-22 11:20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-16 16:40:17</td>\n",
       "      <td>2013-12-16 16:40:18</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:20</td>\n",
       "      <td>2013-12-16 16:40:21</td>\n",
       "      <td>2013-12-16 16:40:22</td>\n",
       "      <td>2013-12-16 16:40:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time1               time2               time3  \\\n",
       "session_id                                                               \n",
       "1          2014-02-20 10:02:45                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:50 2014-02-22 11:19:50 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:17 2013-12-16 16:40:18 2013-12-16 16:40:19   \n",
       "\n",
       "                         time4               time5               time6  \\\n",
       "session_id                                                               \n",
       "1                          NaT                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:51 2014-02-22 11:19:51 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:19 2013-12-16 16:40:19 2013-12-16 16:40:19   \n",
       "\n",
       "                         time7               time8               time9  \\\n",
       "session_id                                                               \n",
       "1                          NaT                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:52 2014-02-22 11:19:52 2014-02-22 11:20:15   \n",
       "3          2013-12-16 16:40:20 2013-12-16 16:40:21 2013-12-16 16:40:22   \n",
       "\n",
       "                        time10  \n",
       "session_id                      \n",
       "1                          NaT  \n",
       "2          2014-02-22 11:20:16  \n",
       "3          2013-12-16 16:40:24  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_duration(data):\n",
    "    values = []\n",
    "    time = time_cols[0]\n",
    "\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "\n",
    "        first = row[time]\n",
    "        last = first\n",
    "\n",
    "        for t, check in zip(time_cols, row.values == np.datetime64('NaT')):\n",
    "            if check:\n",
    "                break\n",
    "            else:\n",
    "                last = row[t]\n",
    "\n",
    "        values.append([np.log1p(last.minute - first.minute)])\n",
    "\n",
    "    return csr_matrix(np.nan_to_num(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [01:24, 2983.45it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_duration = extract_duration(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.98703509379280441, 0.98684183975838335, 0.98953501581344416]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_week(data):\n",
    "    time = time_cols[0]\n",
    "    values = []\n",
    "    \n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        \n",
    "        r = np.zeros(53)\n",
    "        r[row[time].week] = 1\n",
    "        values.append(r)\n",
    "        \n",
    "    return csr_matrix(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:33, 7527.85it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_weeks = extract_week(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_weeks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.98941709369191244, 0.99013409946931674, 0.99101444793886118]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, \n",
    "            X_train_time_features, \n",
    "            X_Train_unique, \n",
    "            X_train_year_month, \n",
    "            X_train_part_of_day, \n",
    "            X_train_weekend,\n",
    "            X_train_duration,\n",
    "            X_train_weeks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.98949889500358323, 0.99018428544527759, 0.99094715463904026]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_train_and_test(data, train_size):\n",
    "#     return X.tocsc()[train_size:], X.tocsc()[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train_df['target'].values.astype('int64')\n",
    "train_test_sites_df = pd.concat([train_df[site_cols].fillna(0).astype('int'), test_df[site_cols].fillna(0).astype('int')])\n",
    "train_test_times_df = pd.concat([train_df[time_cols], test_df[time_cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 336358/336358 [00:14<00:00, 23861.57it/s]\n",
      "336358it [00:32, 10480.73it/s]\n",
      "336358it [00:39, 8479.11it/s] \n",
      "336358it [00:39, 8593.59it/s] \n",
      "336358it [00:29, 11327.54it/s]\n",
      "336358it [00:24, 13507.23it/s]\n",
      "336358it [01:36, 3499.74it/s]\n",
      "336358it [00:33, 10110.49it/s]\n"
     ]
    }
   ],
   "source": [
    "X_tmp_sparse = get_dense_matrix(train_test_sites_df)\n",
    "X_tmp_time_features = exptact_time_features(train_test_times_df)\n",
    "X_tmp_unique = unique(train_test_sites_df)\n",
    "\n",
    "X_tmp_year_month = extract_year_month(train_test_times_df)\n",
    "X_tmp_part_of_day = extract_part_of_day(train_test_times_df)\n",
    "X_tmp_weekend = extract_weekend(train_test_times_df)\n",
    "X_tmp_duration = extract_duration(train_test_times_df)\n",
    "X_tmp_weeks = extract_week(train_test_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test(data, train_size):\n",
    "    return data.tocsc()[:train_size], data.tocsc()[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((336358, 48499), (253561, 48499), (82797, 48499), 253561)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp.shape, X_train.shape, X_test.shape, train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = hstack((X_tmp_sparse, \n",
    "                X_tmp_time_features, \n",
    "                X_tmp_unique, \n",
    "                X_tmp_year_month, \n",
    "#                 X_tmp_part_of_day, \n",
    "#                 X_tmp_weekend,\n",
    "#                 X_tmp_duration,\n",
    "#                 X_tmp_weeks\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 48441)\n",
      "(82797, 48441)\n",
      "Wall time: 44.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_submission(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:12, 20328.86it/s]\n",
      "82797it [00:04, 20555.77it/s]\n"
     ]
    }
   ],
   "source": [
    "str_train = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in tqdm(train_df[site_cols].iterrows())]\n",
    "str_test = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in tqdm(test_df[site_cols].iterrows())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 5)).fit(np.array(str_train))\n",
    "X_train_idf = tfidf.transform(np.array(str_train))\n",
    "X_test_idf = tfidf.transform(np.array(str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = hstack((vstack((X_train_idf, X_test_idf)), \n",
    "                X_tmp_time_features, \n",
    "                X_tmp_unique, \n",
    "                X_tmp_year_month, \n",
    "                X_tmp_part_of_day, \n",
    "                X_tmp_weekend,\n",
    "                X_tmp_duration,\n",
    "                X_tmp_weeks\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.99107908416418244, 0.99274585929596759, 0.99099991104576679]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.99118047658674513, 0.99264331162362274, 0.99086363007977774]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.99070253049763157, 0.99234645093788942, 0.99042369170850275]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.99023887099749275, 0.99203732535030054, 0.98967216321676998]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 2836775)\n",
      "(82797, 2836775)\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_submission(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 1698311)\n",
      "(82797, 1698311)\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_submission(LogisticRegression(C=25, n_jobs=-1), X_train, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 1698311)\n",
      "(82797, 1698311)\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_submission(LogisticRegression(C=19, n_jobs=-1), X_train, y, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.95992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 1698311)\n",
      "(82797, 1698311)\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_submission(LogisticRegression(C=15, n_jobs=-1), X_train, y, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 0.96001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 1698311)\n",
      "(82797, 1698311)\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_submission(LogisticRegression(C=5, n_jobs=-1), X_train, y, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.96000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336358, 1698311)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
